{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import Sequence\n",
    "\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation du CNN de neurone a convolution comme les ANNs\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Convolution2D(filters=32, kernel_size=3, strides=1,\n",
    "                             input_shape=(200, 200, 3),\n",
    "                             activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# ajout de la nouvelle couche de convolution faut pas oublier son pooling\n",
    "classifier.add(Convolution2D(filters=64, kernel_size=3, strides=1,\n",
    "                             activation = \"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a present pour melanger les deux couche de convolution on dois multiplier par 64 filtre a present 32*2\n",
    "\n",
    "classifier.add(Convolution2D(filters=128, kernel_size=3, strides=1,\n",
    "                             activation = \"relu\"))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a present pour melanger les deux couche de convolution on dois multiplier par 64 filtre a present 32*2\n",
    "\n",
    "classifier.add(Convolution2D(filters=128, kernel_size=3, strides=1,\n",
    "                             activation = \"relu\"))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Flattening\n",
    "\"\"\"\n",
    "    -phase d'aprantissage pour obtenir des input pour notre ANNs\n",
    "    \n",
    "elle se fait a la fin pour permettre de renseigner de bonne information au neurone\n",
    "\"\"\"\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: ANNs completement connecté\n",
    "\"\"\"\n",
    "    - Dense = permet d'ajouter une couche de neurone caché\n",
    "        -units= nombre de neurone qui appartiennent a la couche\n",
    "            dans le cas des reseaux de neurone artificielle \n",
    "            on a dis que nous pouvions prendre le nombre de variable ici nous ne poiuvons \n",
    "            pas definir normalement \n",
    "            alors dans notre cas on aura bcp de features faut prendre les nombre \n",
    "            puissance de 2 sa marche tres bien\n",
    "        -activation= represente la fonction d'activation pour cette couche\n",
    "        - relu est tres utiliser pour sa particularité d'etre stricte \n",
    "        soit elle laisse passer le signal ou non\n",
    "\"\"\"\n",
    "classifier.add(Dense(units=256, activation=\"relu\"))\n",
    "classifier.add(Dropout(rate=0.3))\n",
    "classifier.add(Dense(units=256, activation=\"relu\"))\n",
    "classifier.add(Dropout(rate=0.3))\n",
    "classifier.add(Dense(units=256, activation=\"relu\"))\n",
    "classifier.add(Dropout(rate=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definiton de la couche de sortie de notre reseau de neurone a convolution\n",
    "\"\"\"\n",
    " - pour la couche de sortir puisque \n",
    " nous somme tjr dans le contexte de classification \n",
    " alors nous utilisons la fonction sigmoid sinon on aurait utilise dans un cadre c\n",
    " catégorielle la fonction softmax et nous avons juste besoin de 1 neurone\n",
    "\"\"\"\n",
    "classifier.add(Dense(units=6, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etape de compilation de notre reeseau de neurone.\n",
    "\"\"\"\n",
    "    - optimizer= correspond a l'algorithme de macine learning a utiliser pour la classification\n",
    "        adam correspond au stochastique de merde\n",
    "    -loss= represente la fonction de cout binary_cross.. pour la classification et categorical_cros... pour la regression\n",
    "    -metrics= \"accuracy\" \n",
    "    \n",
    "\"\"\"\n",
    "classifier.compile(optimizer=\"adam\",\n",
    "                   loss=\"categorical_crossentropy\",\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2330 images belonging to 6 classes.\n",
      "Found 2330 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'extraire_cadres/activity_data/test/train/images',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'extraire_cadres/activity_data/test/photo_test/images',\n",
    "        target_size=(200, 200),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 375s 5s/step - loss: 0.4257 - accuracy: 0.8342 - val_loss: 14.2442 - val_accuracy: 0.1063\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 385s 5s/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 14.6258 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 392s 5s/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 16.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 390s 5s/step - loss: 6.6680e-04 - accuracy: 1.0000 - val_loss: 15.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 389s 5s/step - loss: 1.6845e-04 - accuracy: 1.0000 - val_loss: 16.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 392s 5s/step - loss: 3.5869e-04 - accuracy: 1.0000 - val_loss: 16.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 393s 5s/step - loss: 2.4662e-05 - accuracy: 1.0000 - val_loss: 16.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 388s 5s/step - loss: 0.0949 - accuracy: 0.9789 - val_loss: 14.4092 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 390s 5s/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 14.5218 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 382s 5s/step - loss: 0.0533 - accuracy: 0.9912 - val_loss: 14.9088 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1dc03d9ed0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=82,\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour enregistrer le model apres entrainement\n",
    "\n",
    "classifier.save('train_avec_cnn_accuracy_faible.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31.127577376692262, 0.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation du modele\n",
    "classifier.evaluate(test_set, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
